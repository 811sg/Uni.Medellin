import pandas as pd
import re
import os
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import PyPDF2
from flask import Flask, request, jsonify
from flask_cors import CORS

# =======================================
# üìã PERFIL IDEAL POR DEFECTO
# =======================================
perfil_ideal = """
Buscamos estudiante para monitor√≠a de An√°lisis de Datos con:
- Dominio de Python (Pandas, NumPy, Matplotlib)
- Conocimientos en estad√≠stica y an√°lisis de datos
- Experiencia previa en ense√±anza, tutor√≠as o monitor√≠as
- Excelente comunicaci√≥n y paciencia
- Promedio superior a 4.0
- Capacidad para explicar conceptos complejos claramente
"""

# =======================================
# ‚öôÔ∏è CONFIGURACIONES GENERALES
# =======================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CARPETA_CVS = os.path.join(BASE_DIR, "hojas_de_vida")

STOP_WORDS = set([
    'el', 'la', 'de', 'en', 'y', 'a', 'los', 'del', 'se', 'las',
    'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'es', 'lo',
    'como', 'm√°s', 'o', 'pero', 'sus', 'le', 'ya', 'fue', 'este',
    'ha', 'si', 'porque', 'esta', 'son', 'entre', 'cuando', 'muy',
    'sin', 'sobre', 'tambi√©n', 'me', 'hasta', 'donde', 'quien', 'desde',
    'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros'
])

# =======================================
# üìÑ FUNCIONES DE PROCESAMIENTO
# =======================================
def extraer_texto_pdf(ruta):
    """Extrae el texto de un PDF."""
    try:
        with open(ruta, 'rb') as f:
            lector = PyPDF2.PdfReader(f)
            texto = ''.join(pagina.extract_text() for pagina in lector.pages)
        return texto if len(texto.strip()) > 50 else None
    except Exception as e:
        print(f"   [!] Error en {os.path.basename(ruta)}: {e}")
        return None


def extraer_nombre(texto, archivo):
    """
    Extrae SOLO nombre + primer apellido del candidato.
    Ejemplo: "Camilo Herrera G√≥mez" ‚Üí "Camilo Herrera"
    """
    # Buscar patr√≥n "Nombre Completo: Camilo Herrera G√≥mez"
    match = re.search(
        r'nombre\s*(?:completo)?:\s*([a-z√°√©√≠√≥√∫√±\s]+?)(?:\n|c√≥digo|correo|tel√©fono|email)',
        texto.lower()
    )
    
    if match:
        nombre_completo = match.group(1).strip().title()
        nombre_completo = re.sub(r'\s+', ' ', nombre_completo)
        
        # üî• IMPORTANTE: Tomar SOLO las primeras 2 palabras (nombre + apellido)
        partes = nombre_completo.split()
        if len(partes) >= 2:
            nombre_corto = f"{partes[0]} {partes[1]}"
            print(f"   üìù Nombre extra√≠do del PDF: '{nombre_completo}' ‚Üí '{nombre_corto}'")
            return nombre_corto
        
        return nombre_completo
    
    # Si no encuentra el nombre en el texto, usar el nombre del archivo
    # Eliminar timestamp y extensi√≥n
    nombre = os.path.splitext(os.path.basename(archivo))[0]
    nombre = re.sub(r'^\d+_', '', nombre)  # Quitar timestamp inicial
    nombre = re.sub(r'^(cv|hoja|vida)_?', '', nombre, flags=re.I)
    nombre = nombre.replace('_', ' ').title()
    
    # Tambi√©n acortar el nombre del archivo
    partes = nombre.split()
    if len(partes) >= 2:
        nombre_corto = f"{partes[0]} {partes[1]}"
        print(f"   üìù Nombre del archivo: '{nombre}' ‚Üí '{nombre_corto}'")
        return nombre_corto
    
    return nombre


def limpiar_texto(texto):
    """Normaliza y limpia el texto eliminando s√≠mbolos y stopwords."""
    texto = texto.lower()
    texto = re.sub(r'[^a-z√°√©√≠√≥√∫√±\s]', ' ', texto)
    palabras = [p for p in texto.split() if len(p) > 2 and p not in STOP_WORDS]
    return ' '.join(palabras)


def analizar_candidatos(perfil, carpeta=CARPETA_CVS):
    """Analiza los CVs de la carpeta seg√∫n el perfil recibido."""
    print("=" * 85)
    print(" SISTEMA DE SELECCI√ìN INTELIGENTE DE MONITORES ".center(85))
    print("=" * 85)
    print()

    if not os.path.exists(carpeta):
        os.makedirs(carpeta)
        print(f"[*] Carpeta '{carpeta}' creada. Coloca los PDFs ah√≠.\n")
        return None

    pdfs = [f for f in os.listdir(carpeta) if f.endswith('.pdf')]
    if not pdfs:
        print(f"[X] No hay archivos PDF en '{carpeta}'\n")
        return None

    print(f"[*] Carpeta: {carpeta}")
    print(f"[*] PDFs encontrados: {len(pdfs)}\n")
    print("[*] Leyendo archivos...")

    candidatos = []
    for i, pdf in enumerate(pdfs, 1):
        ruta = os.path.join(carpeta, pdf)
        print(f"   {i}. {pdf}...", end=" ")

        texto = extraer_texto_pdf(ruta)
        if texto:
            nombre_extraido = extraer_nombre(texto, pdf)
            texto_limpio = limpiar_texto(texto)
            candidatos.append({
                'Nombre': nombre_extraido,
                'Archivo': pdf,
                'Texto': texto_limpio
            })
            print(f"[OK] - {len(texto_limpio.split())} palabras procesadas")
        else:
            print("[ERROR]")

    if not candidatos:
        print("\n[X] No se pudo procesar ning√∫n PDF\n")
        return None

    print(f"\n[OK] {len(candidatos)} CVs procesados correctamente\n")

    df = pd.DataFrame(candidatos)

    # =======================================
    # üß† AN√ÅLISIS DE SIMILITUD (IA MEJORADA)
    # =======================================
    print("[*] Analizando con IA (TF-IDF + Similitud de Coseno)...")

    perfil_limpio = limpiar_texto(perfil)
    print(f"[*] Palabras clave del perfil: {len(perfil_limpio.split())}")
    
    textos = df['Texto'].tolist() + [perfil_limpio]

    # üî• CONFIGURACI√ìN MEJORADA DEL VECTORIZADOR
    vectorizer = TfidfVectorizer(
        max_features=1000,        # M√°s features para mejor precisi√≥n
        ngram_range=(1, 3),       # Considera frases de 1-3 palabras
        min_df=1,                 # Incluir t√©rminos aunque aparezcan 1 vez
        sublinear_tf=True,        # Escalado logar√≠tmico
        strip_accents='unicode'   # Normalizar acentos
    )
    
    matriz_tfidf = vectorizer.fit_transform(textos)

    # üîπ Calcular similitud entre perfil y CVs
    similitudes = cosine_similarity(matriz_tfidf[-1], matriz_tfidf[:-1]).flatten()
    df['Score'] = similitudes

    # üîπ Ordenar candidatos de mayor a menor similitud
    df = df.sort_values('Score', ascending=False).reset_index(drop=True)

    print(f"[OK] An√°lisis completado\n")
    print("=" * 85)
    print(" RANKING DE CANDIDATOS ".center(85))
    print("=" * 85)
    print()

    for i, row in df.iterrows():
        prefijo = ["[1]", "[2]", "[3]"][i] if i < 3 else f"[{i+1}]"
        barra = "‚ñà" * int(row['Score'] * 50)
        print(f"{prefijo} {row['Nombre']}")
        print(f"      Score: {row['Score']:.4f} ({row['Score']*100:.1f}%) [{barra}]")
        print(f"      Archivo: {row['Archivo']}\n")

    print("[*] Resultados guardados en: ranking_monitores.csv\n")
    df[['Nombre', 'Archivo', 'Score']].to_csv('ranking_monitores.csv', index=False)

    return df


# =======================================
# üåê SERVIDOR FLASK (Integraci√≥n con Node.js)
# =======================================
app = Flask(__name__)
CORS(app)

@app.route("/analizar", methods=["POST"])
def analizar():
    try:
        data = request.get_json()
        perfil = data.get("perfil", None)
        if perfil is None or len(perfil.strip()) < 20:
            perfil = perfil_ideal

        print(f"\n[*] ü§ñ An√°lisis recibido desde Node.js")
        print(f"[*] Perfil: {perfil[:80].strip()}...\n")
        
        df = analizar_candidatos(perfil)

        if df is None or df.empty:
            print("[‚ö†Ô∏è] No se encontraron CVs v√°lidos.")
            return jsonify({"error": "No se encontraron CVs v√°lidos."}), 400

        # üî• Devolver scores sin multiplicar (como decimales)
        resultados = [
            {
                "nombre": row["Nombre"],
                "archivo": row["Archivo"],
                "puntaje": round(float(row["Score"]), 4)
            }
            for _, row in df.iterrows()
        ]

        print(f"[‚úÖ] Resultados generados ({len(resultados)} candidatos):")
        for r in resultados:
            print(f"   ‚Ä¢ {r['nombre']}: {r['puntaje']*100:.2f}%")
        print()
        
        return jsonify(resultados)

    except Exception as e:
        print(f"[‚ùå] Error al analizar: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


if __name__ == "__main__":
    print("\nüåê SERVIDOR IA ACTIVO ‚Äî CONECTADO A NODE.JS")
    print(f"üìÇ Carpeta de an√°lisis: {os.path.abspath(CARPETA_CVS)}")
    print("üîó Endpoint: http://127.0.0.1:5000/analizar")
    print("=" * 85)
    print()
    app.run(host="127.0.0.1", port=5000, debug=False)